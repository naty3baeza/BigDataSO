{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTRODUCCION A PYSPARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importo la libreria\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#abro una sesion con un nombre\n",
    "spark=SparkSession.builder.appName('pysarkpruebas').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leo un archivo de HDFS\n",
    "#header true es para que la primera fila sea considerada los atributos y no una tupla mas\n",
    "#inferschema es para que tome los tipos de datos como son, no toso string..prueben poner false y luego imprimir el esquema\n",
    "df_nba = spark.read.csv('hdfs://127.0.0.1:9000/so/username.csv', header=True,  inferSchema=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Username; Identifier;First name;Last name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#mostrar el esquema que interpretó en el header\n",
    "df_nba.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Path does not exist: hdfs://127.0.0.1:9000/cursoFAI/movie.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-189bf13e9670>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#leo otro archivo HDFS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_movie\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hdfs://127.0.0.1:9000/cursoFAI/movie.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferSchema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#mostrar el esquema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_movie\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark3/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env3/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark3/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Path does not exist: hdfs://127.0.0.1:9000/cursoFAI/movie.csv"
     ]
    }
   ],
   "source": [
    "#leo otro archivo HDFS \n",
    "df_movie = spark.read.csv('hdfs://127.0.0.1:9000/so/username.csv', header=True, inferSchema=True)\n",
    "#mostrar el esquema\n",
    "df_movie.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mostrar solo las primeras 3 tuplas de movie\n",
    "df_movie.show(3)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------+\n",
      "|genres                                     |\n",
      "+-------------------------------------------+\n",
      "|Adventure|Animation|Children|Comedy|Fantasy|\n",
      "|Adventure|Children|Fantasy                 |\n",
      "|Comedy|Romance                             |\n",
      "|Comedy|Drama|Romance                       |\n",
      "|Comedy                                     |\n",
      "|Action|Crime|Thriller                      |\n",
      "|Comedy|Romance                             |\n",
      "|Adventure|Children                         |\n",
      "|Action                                     |\n",
      "|Action|Adventure|Thriller                  |\n",
      "+-------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#mostrar las primeras 4 tuplas de la columna genres\n",
    "#el parámetro falso avisa que no trunque el resultado de la columna (do not truncate)\n",
    "df_movie.select('genres').show(10, False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------+----------------------------------+\n",
      "|genres                                     |title                             |\n",
      "+-------------------------------------------+----------------------------------+\n",
      "|Adventure|Animation|Children|Comedy|Fantasy|Toy Story (1995)                  |\n",
      "|Adventure|Children|Fantasy                 |Jumanji (1995)                    |\n",
      "|Comedy|Romance                             |Grumpier Old Men (1995)           |\n",
      "|Comedy|Drama|Romance                       |Waiting to Exhale (1995)          |\n",
      "|Comedy                                     |Father of the Bride Part II (1995)|\n",
      "|Action|Crime|Thriller                      |Heat (1995)                       |\n",
      "|Comedy|Romance                             |Sabrina (1995)                    |\n",
      "|Adventure|Children                         |Tom and Huck (1995)               |\n",
      "|Action                                     |Sudden Death (1995)               |\n",
      "|Action|Adventure|Thriller                  |GoldenEye (1995)                  |\n",
      "+-------------------------------------------+----------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#mostrar las primeras 4 tuplas de la columna genres y title\n",
    "df_movie.select('genres','title').show(10, False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#leo un 3er archivo HDFS \n",
    "df_rating = spark.read.csv('hdfs://127.0.0.1:9000/cursoFAI/rating.csv', header=True,  inferSchema=True)\n",
    "#mostrar el esquema\n",
    "df_rating.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-------------------+\n",
      "|userId|movieId|rating|          timestamp|\n",
      "+------+-------+------+-------------------+\n",
      "|     1|      2|   3.5|2005-04-02 23:53:47|\n",
      "|     1|     29|   3.5|2005-04-02 23:31:16|\n",
      "|     1|     32|   3.5|2005-04-02 23:33:39|\n",
      "+------+-------+------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#mostrar solo las primeras 3 tuplas de movie\n",
    "df_rating.show(3)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('userId', 'int'),\n",
       " ('movieId', 'int'),\n",
       " ('rating', 'double'),\n",
       " ('timestamp', 'string')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mostrar los tipos de datos de la tabla rating\n",
    "df_rating.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la cantidad de tuplas de rating es:  20000263\n"
     ]
    }
   ],
   "source": [
    "#contar la cantidad de tuplas de rating\n",
    "print(\"la cantidad de tuplas de rating es: \",df_rating.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la cantidad de tuplas de movie es:  27278\n"
     ]
    }
   ],
   "source": [
    "#contar la cantidad de tuplas de movies\n",
    "print(\"la cantidad de tuplas de movie es: \", df_movie.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138493"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#contar la cantidad de users diferentes en ratings\n",
    "df_rating.select('userId').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-------------------+\n",
      "|userId|movieId|rating|          timestamp|\n",
      "+------+-------+------+-------------------+\n",
      "|     1|      2|   3.5|2005-04-02 23:53:47|\n",
      "|     1|     29|   3.5|2005-04-02 23:31:16|\n",
      "|     1|     32|   3.5|2005-04-02 23:33:39|\n",
      "|     1|     47|   3.5|2005-04-02 23:32:07|\n",
      "|     1|     50|   3.5|2005-04-02 23:29:40|\n",
      "+------+-------+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#crear un nuevo dataframe con las 1ras 5 filas de rating\n",
    "df_nuevo= df_rating.limit(5)\n",
    "df_nuevo.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-------------------+\n",
      "|userId|movieId|rating|          timestamp|\n",
      "+------+-------+------+-------------------+\n",
      "|     1|      2|   3.5|2005-04-02 23:53:47|\n",
      "|     1|     29|   3.5|2005-04-02 23:31:16|\n",
      "|     1|     32|   3.5|2005-04-02 23:33:39|\n",
      "|     1|     47|   3.5|2005-04-02 23:32:07|\n",
      "|     1|     50|   3.5|2005-04-02 23:29:40|\n",
      "|     1|    112|   3.5|2004-09-10 03:09:00|\n",
      "|     1|    151|   4.0|2004-09-10 03:08:54|\n",
      "|     1|    223|   4.0|2005-04-02 23:46:13|\n",
      "|     1|    253|   4.0|2005-04-02 23:35:40|\n",
      "|     1|    260|   4.0|2005-04-02 23:33:46|\n",
      "+------+-------+------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rating.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|movieId|count|\n",
      "+-------+-----+\n",
      "|   3997| 2047|\n",
      "|   1580|35580|\n",
      "|   3918| 1246|\n",
      "|   2366| 6627|\n",
      "|   3175|13945|\n",
      "|   4519| 1936|\n",
      "|   1591| 5255|\n",
      "|    471|11268|\n",
      "|  36525| 1169|\n",
      "|  44022| 2465|\n",
      "|   2866| 1407|\n",
      "|   1645|11458|\n",
      "|   5803| 1046|\n",
      "|  54190| 1687|\n",
      "|   1088|11013|\n",
      "|    833| 1427|\n",
      "|   8638| 3449|\n",
      "|    463|  410|\n",
      "|   1959| 5016|\n",
      "|   2659|  260|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#agrupar rating  por la columna movieId y contar el resultado\n",
    "df_rating.groupBy(\"movieId\").count().show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|rating|  count|\n",
      "+------+-------+\n",
      "|   3.5|2200156|\n",
      "|   4.5|1534824|\n",
      "|   2.5| 883398|\n",
      "|   1.0| 680732|\n",
      "|   4.0|5561926|\n",
      "|   0.5| 239125|\n",
      "|   3.0|4291193|\n",
      "|   2.0|1430997|\n",
      "|   1.5| 279252|\n",
      "|   5.0|2898660|\n",
      "+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#agrupar rating  por la columna rating\n",
    "df_rating.groupBy('rating').count().show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|movieId|count|\n",
      "+-------+-----+\n",
      "|   3997| 2047|\n",
      "|   1580|35580|\n",
      "|   3918| 1246|\n",
      "|   2366| 6627|\n",
      "|   3175|13945|\n",
      "|   4519| 1936|\n",
      "|   1591| 5255|\n",
      "|    471|11268|\n",
      "|  36525| 1169|\n",
      "|  44022| 2465|\n",
      "|   2866| 1407|\n",
      "|   1645|11458|\n",
      "|   5803| 1046|\n",
      "|  54190| 1687|\n",
      "|   1088|11013|\n",
      "|    833| 1427|\n",
      "|   8638| 3449|\n",
      "|    463|  410|\n",
      "|   1959| 5016|\n",
      "|   2659|  260|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#agrupar rating  por la columna movieId\n",
    "df_rating.groupBy('movieId').count().show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[movieId: int, avg(rating): double]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#agrupo por movieId y saco el promedio de rating que tiene\n",
    "df_rating.groupby('movieId').mean('rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|movieId|       avg(rating)|\n",
      "+-------+------------------+\n",
      "|   3997|2.0703468490473864|\n",
      "|   1580|  3.55831928049466|\n",
      "|   3918| 2.918940609951846|\n",
      "|   2366|3.5492681454655197|\n",
      "|   3175| 3.600717102904267|\n",
      "|   4519|3.2463842975206614|\n",
      "|   1591|2.6201712654614653|\n",
      "|    471|3.6641817536386228|\n",
      "|  36525| 3.482891360136869|\n",
      "|  44022| 3.334077079107505|\n",
      "|   2866| 3.605188343994314|\n",
      "|   1645|3.4787484726828417|\n",
      "|   5803| 2.772944550669216|\n",
      "|  54190|3.6701244813278007|\n",
      "|   1088| 3.209207300463089|\n",
      "|    833| 2.725998598458304|\n",
      "|   8638|3.9375181211945494|\n",
      "|    463|               2.8|\n",
      "|   1959| 3.628987240829346|\n",
      "|   2659|3.2326923076923078|\n",
      "+-------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ahora lo muestro\n",
    "df_rating.groupby('movieId').mean('rating').show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-------------------+\n",
      "|userId|movieId|rating|          timestamp|\n",
      "+------+-------+------+-------------------+\n",
      "|     1|   1196|   4.5|2005-04-02 23:32:22|\n",
      "|     1|   1198|   4.5|2005-04-02 23:30:24|\n",
      "|     1|   4993|   5.0|2005-04-02 23:31:22|\n",
      "|     1|   5952|   5.0|2005-04-02 23:30:19|\n",
      "|     1|   7153|   5.0|2005-04-02 23:30:33|\n",
      "|     1|   8507|   5.0|2004-09-10 03:13:47|\n",
      "|     1|   8636|   4.5|2005-04-02 23:44:53|\n",
      "|     2|     62|   5.0|2000-11-21 15:29:58|\n",
      "|     2|     70|   5.0|2000-11-21 15:31:31|\n",
      "|     2|    260|   5.0|2000-11-21 15:36:54|\n",
      "+------+-------+------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#aplicando filtros (como un where de SQL)\n",
    "#mostrar los rating mayores a 4\n",
    "df_rating.filter(df_rating['rating'] > 4).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la cantidad de NO nulos es:  20000263\n"
     ]
    }
   ],
   "source": [
    "#cuantas valores nulos tiene userId?\n",
    "print(\"la cantidad de NO nulos es: \", df_rating.filter(df_rating.rating.isNotNull()).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la cantidad de NO nulos es:  0\n"
     ]
    }
   ],
   "source": [
    "#cuantas valores no nulos tiene userId?\n",
    "print(\"la cantidad de NO nulos es: \", df_rating.filter(df_rating.rating.isNull()).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creo una tabla desde el csv de rating\n",
    "df_rating.createOrReplaceTempView(\"tablaRating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|userId|\n",
      "+------+\n",
      "|     1|\n",
      "|     1|\n",
      "|     1|\n",
      "|     1|\n",
      "|     1|\n",
      "+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# y ahora puedo hacer clq consulta con la sintaxis tipica de SQL.\n",
    "# usamos la sesión de spark creada al ppio\n",
    "resultado = spark.sql(\"SELECT userId FROM tablaRating WHERE rating > 4\")\n",
    "resultado.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
